

在早期的计算机内存非常小，一次只能运行一个进程，运行完毕才能运行将下一个进程运行，运行中的进程能直接访问所有的物理内存，而不会跟其它进程冲突，也不用担心被其它进程修改。

现代操作系统中，同时运行多个应用程序太正常不多了，一边听着网易云音乐，一边微信聊天。对于内存管理而已，当有多个进程同时运行时，情况就复杂很多了，你需要考虑如何划分内存，如何保证进程之间内存不会互相修改，如何处理物理内存的碎片化等等。

为了解决这些问题，在多任务的操作系统中引入了「虚拟内存」的概念，程序员不去直接操作物理内存，每个进程都运行在自己独立的内存空间里，可以想象为一个内存沙盒，如下图所示：

![virtual_memory](//p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3c9bd444cdcb4bfb8e8ac80a026b33f9~tplv-k3u1fbpfcp-zoom-1.image)


以下面的两个程序 `virtual_memory_01.c` 和 `virtual_memory_02.c` 代码为例，来直观感受一下虚拟内存。


```c
virtual_memory_01.c

#include <stdio.h>
#include <stdlib.h>
int main() {
    char *ptr = malloc(1 * 1024 * 1024);
    printf("ptr in test1: %p\n", ptr);
    getchar();
    return 0;
}

virtual_memory_02.c
#include <stdio.h>
#include <stdlib.h>
int main() {
    char *ptr = malloc(1 * 1024 * 1024);
    printf("ptr in test2: %p\n", ptr);
    getchar();
    return 0;
}
```

首先关闭内存地址随机化（为什么要做这一步我们后面会再谈）：

```
sudo sysctl -w kernel.randomize_va_space=0 
```

然后编译执行这两个程序：

```
gcc virtual_memory_01.c -o virtual_memory_01
gcc virtual_memory_02.c -o virtual_memory_02

./virtual_memory_01                                                                             
ptr in test1: 0x7ffff7eec010

./virtual_memory_02
ptr in test2: 0x7ffff7eec010
```

可以看到这两个程序申请到的 1M 空间的地址首地址都是 0x7ffff7eec010，这个值在你的环境可能会不一样，示意图如下所示：

![virtual_memory](//p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6faf2cdd91b64ff89ea6284d55a93497~tplv-k3u1fbpfcp-zoom-1.image)


这个沙盒被称为虚拟地址空间（Virtual Address Space）。这样印证了进程是资源的封装单位这个说法。

操作系统允许程序使用的内存大小与操作系统位数有关。


一般文中出现虚拟的东西，大都不是真实存在的。虚拟地址空间就是以程序员视角，操作系统提供的一个可操作空间。很形象的比喻就是你找银行贷款，银行说能给你贷款数额 5-100w，这个区间就是你借款区间，至于真正能不能贷款到指定数额的，还得看你的财务状态和银行的现金流情况。这里也是类似的，虚拟地址就是我们程序能访问的最大范围，到底能不能达到这个范围，还需要操作系统和硬件根据当前机器运行状态是否能支持。


## 32 位和 64 位系统的虚拟地址空间

在 32 位系统中，虚拟地址空间的大小为 4GB（2^32），范围如下：

```
0x00000000 ~ 0xffffffff
```

在 4GB 的空间又被分为两部分，用户空间和内核空间，默认情况下用户空间占 3G，内核空间占 1G，如下图所示。


这个值可以通过 VMSPLIT 内核选项修改为 2G:2G 等不同的大小占比。

在 64 位系统中，理论上最大能寻址 2^64 ，这个值非常大，实际上虚拟地址的空间只用了其中的 48 位，内核空间和用户空间各占 128TB，如下图所示。

<p align=center><img src="//p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e0dd2013c74f43edbc5ab5203815bb90~tplv-k3u1fbpfcp-zoom-1.image" alt="process_memory-1"  width="70%"/></p>


用户空间的高地址值是 0x7FFFFFFFF000，源码中的定义如下：

```
#define TASK_SIZE_MAX	((1UL << 47) - PAGE_SIZE)
```

其中的 PAGE_SIZE 为 4k，计算的过程如下：

```
0x7FFFFFFFF000 = ((1 << 47) - PAGE_SIZE)
```

这里的 1 左移 47 位，相当于 48 位地址空间一半的大小 0x800000000000，然后减去的一个页的大小 PAGE_SIZE(4096)，这一页的作用是作为 Guard 区域。

说完了用户空间，接下来来看内核空间，内核空间的低地址值为 0xFFFF800000000000，它在源码中的定义如下：

```
#define __START_KERNEL_map	_AC(0xffffffff80000000, UL)
```

## 验证

为了验证上面的说法，可以写一个简单的 systemtap 脚本来验证，进程创建时， task_struct 的 mm 变量的 task_size 被赋值为了 TASK_SIZE，只需要打印这个变量即可。

```
current->mm->task_size = TASK_SIZE;
```

systemtap 的脚本如下所示：

```
%{
#include <linux/list.h>
#include <linux/sched.h>
%}

function process_list ()
%{
    struct task_struct *p;
    for_each_process(p) {
        if (p->mm != NULL) {
            _stp_printf("process: %s, task_size: 0x%lx\n", p->comm, p->mm->task_size);
        }
    }
%}
probe begin {
    process_list();
    exit();
}
```

使用 stap 执行上面的脚本，会打印所有进程的 task_size，如下所示：


```
sudo stap -g task_list.stp

...
process: sshd, task_size: 0x7ffffffff000
process: sshd, task_size: 0x7ffffffff000
process: zsh, task_size: 0x7ffffffff000
process: a.out, task_size: 0x7ffffffff000
process: sudo, task_size: 0x7ffffffff000
```



## MMU

前面提到，应用进程看到的内存地址都是虚拟内存地址，操作系统通过「地址转换」来完成虚拟地址到物理地址的映射，这个过程通过一个叫做 MMU（Memory Management Unit）的硬件单元来完成，如下图所示：

![mmu](//p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f96b4a48e18146a99c52f01e3d2c777d~tplv-k3u1fbpfcp-zoom-1.image)

前面提到的 virtual_memory_01 和  virtual_memory_02 测试程序一个可能的映射情况如下：

![mmu_02](//p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/841fbfa7fb924c88ad3b5310f1ed5cf5~tplv-k3u1fbpfcp-zoom-1.image)

进程 1 中看到的连续的虚拟内存在实际的虚拟内存中完全有可能不连续，可能会分割为多个小的内存区块，如下图所示：

![mmu-memory-not-continuation](//p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/36d0b96766164fe9b896c58df8674b63~tplv-k3u1fbpfcp-zoom-1.image)
                                                                           

## 页表：实现虚拟地址空间映射到物理地址空间的数据结构

实际上内核通过「页表（page table）」这个数据结构实现了虚拟内存地址到物理内存地址的转换。

一般一页的大小为 4k，4k 等于 2^12 ，虚拟地址中的低 12 位其实是一个偏移量。以 32 位内存地址为例，页表中的高 20 位是虚拟地址的页号，低 12 位为页内偏移量。


现在我们把页表想象为一个一维数组，对于虚拟地址中的每一页，都分配数组的一个槽位，这个槽位指向物理地址中的真正地址。那么有这么一个虚拟内存地址 0x1234010，那 0x010 就是页内偏移量，0x1234 是虚拟页号，CPU 通过 MMU 找到 0x1234 映射的物理内存页地址，假定为 0x2b601000，然后加上页内偏移 0x010，就找到了真正的物理内存地址 0x2b601010。如下图所示：

![vitual_memory_mapping](//p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/02809ceb373b4dddac3dad6c93bff894~tplv-k3u1fbpfcp-zoom-1.image)


但是这种方式有一个很明显的问题，虚拟地址空间可能会非常大，就算拿 32 位的系统为例，虚拟地址空间为 4GB，用户空间内存大小为 3GB，每页大小为 4kB，数组的大小为 786432(1024 * 1024)。每个页表项用 4 个字节来存储，这样 4GB 的空间映射就需要 3MB的内存来存储映射表。

对于单个进程来说，占用 3M 看起来没有什么，但是页表是进程独占的，每个进程都需要自己的页表，如果有一百个进程，就会占用 300MB 的内存，这还仅仅是做地址映射所花的内存。如果考虑 64 位系统超大虚拟地址空间的情况，这种一维的数组实现的方式更加不切实际。

为了解决这个问题，人们使用了 level 的概念，页表的结构分为多级，页表项的大小只与虚拟内存空间中真正使用的多少有关。之前一维数组表示的方式页表项的多少与虚拟地址空间的大小成正比，这种多级结构的方式使得没有使用的内存不用分配页表项。

于是人们想出了多级页表的形式，这种方式非常适合，因为大部分区域的虚拟地址空间实际上是没有使用的，使用多级页表可以显著的减少页表本身的内存占用。在 64 位系统上，Linux 采用了四级页表：

- PGD：Page Global Directory，页全局目录，是顶级页表。
- PUD：Page Upper Directory，页上级目录，是第二级页表
- PMD：Page Middle Derectory，页中间目录，是第三级页表。
- PTE：Page Table Entry，页面表，最后一级页表，指向物理页面。

如下图所示：

![level-4-pagetable](//p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fe07e7327acd4eeaabc2e7416bf301a0~tplv-k3u1fbpfcp-zoom-1.image)

有了上面基础，我们可以来写一个内核模块来把虚拟地址转为真正的物理地址。

完整的代码如下所示：

```
/**
 * 原始代码来自 Stack Overflow（https://stackoverflow.com/questions/41090469/linux-kernel-how-to-get-physical-address-memory-management）
 * 做了一些修改，可以处理用户传入的 pid 和 address
 */
#include  <linux/module.h>
#include <linux/kernel.h>
#include <linux/init.h>
#include <linux/sched.h>
#include <linux/pid.h>
#include <linux/mm.h>
#include <asm/pgtable.h>
#include <asm/page.h>

static pid_t pid;
module_param(pid, int,0644);

static unsigned long va;
module_param(va, ulong, 0644);


static void print_pgtable_macro(void) {
    printk("PAGE_OFFSET = 0x%lx\n", PAGE_OFFSET);
    printk("PGDIR_SHIFT = %d\n", PGDIR_SHIFT);
    printk("PUD_SHIFT = %d\n", PUD_SHIFT);
    printk("PMD_SHIFT = %d\n", PMD_SHIFT);
    printk("PAGE_SHIFT = %d\n", PAGE_SHIFT);

    printk("PTRS_PER_PGD = %d\n", PTRS_PER_PGD);
    printk("PTRS_PER_PUD = %d\n", PTRS_PER_PUD);
    printk("PTRS_PER_PMD = %d\n", PTRS_PER_PMD);
    printk("PTRS_PER_PTE = %d\n", PTRS_PER_PTE);

    printk("PAGE_MASK = 0x%lx\n", PAGE_MASK);
}
int my_module_init(void) {
    print_pgtable_macro();
    printk("\n");

    unsigned long pa = 0;

    pgd_t *pgd = NULL;
    pud_t *pud = NULL;
    pmd_t *pmd = NULL;
    pte_t *pte = NULL;

    struct pid *p = NULL;
    struct task_struct *task_struct = NULL;

    p = find_vpid(pid);
    if (p == NULL) {
        printk("find_vpid is null\n");
        return -1;
    }

    task_struct = pid_task(p, PIDTYPE_PID);
    if (task_struct == NULL) {
        printk("pid_task is null\n");
        return -1;
    }

    pgd = pgd_offset(task_struct->mm, va);
    printk("pgd_val = 0x%lx\n", pgd_val(*pgd));
    printk("pgd_index = %lu\n", pgd_index(va));

    if (pgd_none(*pgd)) {
        printk("Not mapped in pgd.\n");
        return -1;
    }
    pud = pud_offset(pgd, va);
    printk("pud_val = 0x%lx\n", pud_val(*pud));
    printk("pud_index = %lu\n", pud_index(va));

    if (pud_none(*pud)) {
        printk("Not mapped in pud.\n");
        return 0;
    }
    pmd = pmd_offset(pud, va);
    printk("pmd_val = 0x%lx\n", pmd_val(*pmd));
    printk("pmd_index = %lu\n", pmd_index(va));

    if (pmd_none(*pmd)) {
        printk("Not mapped in pmd.\n");
        return 0;
    }
    pte = pte_offset_kernel(pmd, va);

    printk("pte_val = 0x%lx\n", pte_val(*pte));
    printk("pte_index = %lu\n", pte_index(va));

    if (pte_none(*pte)) {
        printk("Not mapped in pte.\n");
        return 0;
    }
    if (!pte_present(*pte)) {
        printk("pte not in RAM.\n");
        return 0;
    }
    unsigned long page_addr = 0;
    unsigned long page_offset = 0;
    page_addr = pte_val(*pte) & PAGE_MASK;
    page_addr &= 0x7fffffffffffffULL;

    page_offset = va & ~PAGE_MASK;
    pa = page_addr | page_offset;

    printk("page_addr = 0x%lx, page_offset = 0x%03lx\n", page_addr, page_offset);
    printk("virtual address 0x%lx in RAM Page is 0x%lx\n", va, pa);

    return 0;
}
void my_module_exit(void) {
    printk("module exit!\n");
}

module_init(my_module_init);
module_exit(my_module_exit);

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Arthur.Zhang");
MODULE_DESCRIPTION("A simple virtual memory inspect");

```

然后写一个 Makefile：

```
obj-m += my_mem.o
all:
	make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean
insmod:
	sudo insmod my_mem.ko
rmmod:
	sudo rmmod my_mem.ko
```

测试的程序如下所示：
```
#include <stdlib.h>
#include <stdio.h>
#include <unistd.h>
int main() {
    char *p = NULL;
    p = malloc(1024 * 1024);
    *p = 0;
    printf("ptr: %p, pid: %d\n", p, getpid());
    getchar();
    return 0;
}
```
运行上面的代码会打印当前的 pid 和虚拟地址的值，如下所示：

```
ptr: 0x7ffff7eec010, pid: 2621
```
然后编译内核模块，传入 pid 和虚拟内存地址：

```
make all
sudo make rmmod
sudo insmod my_mem.ko pid=7251 va=0x7ffff7eec010
```

然后执行 dmesg -T，就可以看到 pgd 等值以及真正的物理地址的值了。

```
[Sat Oct 10 05:11:12 2020] PAGE_OFFSET = 0xffff880000000000
[Sat Oct 10 05:11:12 2020] PGDIR_SHIFT = 39
[Sat Oct 10 05:11:12 2020] PUD_SHIFT = 30
[Sat Oct 10 05:11:12 2020] PMD_SHIFT = 21
[Sat Oct 10 05:11:12 2020] PAGE_SHIFT = 12
[Sat Oct 10 05:11:12 2020] PTRS_PER_PGD = 512
[Sat Oct 10 05:11:12 2020] PTRS_PER_PUD = 512
[Sat Oct 10 05:11:12 2020] PTRS_PER_PMD = 512
[Sat Oct 10 05:11:12 2020] PTRS_PER_PTE = 512
[Sat Oct 10 05:11:12 2020] PAGE_MASK = 0xfffffffffffff000

[Sat Oct 10 05:11:12 2020] pgd_val = 0x237a97067
[Sat Oct 10 05:11:12 2020] pgd_index = 255
[Sat Oct 10 05:11:12 2020] pud_val = 0x235f0d067
[Sat Oct 10 05:11:12 2020] pud_index = 511
[Sat Oct 10 05:11:12 2020] pmd_val = 0x23b61f067
[Sat Oct 10 05:11:12 2020] pmd_index = 447
[Sat Oct 10 05:11:12 2020] pte_val = 0x80000002358a4867
[Sat Oct 10 05:11:12 2020] pte_index = 236
[Sat Oct 10 05:11:12 2020] page_addr = 0x2358a4000, page_offset = 0x010
[Sat Oct 10 05:11:12 2020] virtual address 0x7ffff7eec010 in RAM Page is 0x2358a4010
```

在这次的实验中，虚拟地址的值为 0x7ffff7eec010，对应的物理地址的值为 0x2358a4010。

